{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPmAnIfFnUxnygKNKqgEjRZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/you0229/kaggle_titanic/blob/master/main_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGwnZ6RpKtyn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "e94fd0fb-a480-445b-f83e-63e0fb3044d1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RD6-RJwnKUZx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        },
        "outputId": "420aca38-3245-4081-9e52-610362776561"
      },
      "source": [
        "# libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "# %matplotlib inline\n",
        "\n",
        "COLAB_FLG = 1\n",
        "TRAIN_PATH = '/kaggle/input/titanic/train.csv'\n",
        "TEST_PATH = '/kaggle/input/titanic/test.csv'\n",
        "COLAB_TRAIN_PATH = '/content/drive/My Drive/MachineLeaning/kaggle_titanic/train.csv'\n",
        "COLAB_TEST_PATH = '/content/drive/My Drive/MachineLeaning/kaggle_titanic/test.csv'\n",
        "\n",
        "# データ読み込み\n",
        "def read_data():\n",
        "  ## 読み込むデータのパス切り替え\n",
        "  if COLAB_FLG:\n",
        "    TRAIN_PATH = COLAB_TRAIN_PATH\n",
        "    TEST_PATH = COLAB_TEST_PATH\n",
        "  \n",
        "  print('Train data reading...')\n",
        "  train = pd.read_csv(TRAIN_PATH)\n",
        "  print(\"Train data is column {}, rows: {}\".format(train.shape[0], train.shape[1]))\n",
        "  print('Test data reading...')\n",
        "  test = pd.read_csv(TEST_PATH)\n",
        "  print(\"Test data is column {}, rows: {}\".format(test.shape[0], test.shape[1]))\n",
        "\n",
        "  return train, test\n",
        "\n",
        "# データ整理\n",
        "def pre_processing(train, test):\n",
        "  # train と test を合わせて前処理\n",
        "  print('Combine train and test')\n",
        "  train['is_train'] = 1\n",
        "  test['is_train'] = 0\n",
        "  train_test = pd.concat([train.drop('Survived', axis=1),test], axis=0)\n",
        "\n",
        "  # Sex\n",
        "  print('Modifying Sex column')\n",
        "  train_test = train_test.replace('female', 0).replace('male', 1)\n",
        "\n",
        "  # Ticket\n",
        "  print('Modifying Ticket column')\n",
        "  ticket_to_num = {'A':0, 'P':1, 'S':2, '1':3, '3':4, '2':5, 'C':6, '7':7, 'W':8, '4':9, 'F':9, 'L':10, '9':11,'6':12, '5':13, '8':14}\n",
        "  train_test['Ticket_Left'] = train_test['Ticket'].apply(lambda x: str(x)[0])\n",
        "  train_test['Ticket_Left'] = train_test['Ticket_Left'].replace(ticket_to_num)\n",
        "  train_test = train_test.drop('Ticket', axis=1)\n",
        "\n",
        "  # Embarked\n",
        "  print('Modifying Embarked column')\n",
        "  embarked_to_num = {'S':0, 'C':1, 'Q':2}\n",
        "  train_test['Embarked'] = train_test['Embarked'].replace(embarked_to_num)\n",
        "  train_test['Embarked'] = train_test['Embarked'].fillna(train_test['Embarked'].mean())\n",
        "  train_test = train_test.drop('Embarked', axis=1)\n",
        "\n",
        "  # Cabin\n",
        "  # 204/891 したデータが入っていないため削除\n",
        "  print('Modifying Cabin column')\n",
        "  train_test = train_test.drop('Cabin', axis=1)\n",
        "\n",
        "  # Age\n",
        "  # print('Modifying Age column')\n",
        "  # train_test = train_test.dropna(subset=['Age'])\n",
        "\n",
        "  # Name\n",
        "  # 関係なさそうだから削除\n",
        "  print('Modifying Name column')\n",
        "  train_test = train_test.drop('Name', axis=1)\n",
        "\n",
        "  # Fare\n",
        "  # print('Modifying Fare column')\n",
        "  # train_test = train_test.dropna(subset=['Fare'])\n",
        "\n",
        "  # train test\n",
        "  print('Split train and test')\n",
        "  train_result = train_test.loc[train_test['is_train'] == 1]\n",
        "  test_result = train_test.loc[train_test['is_train'] == 0]\n",
        "\n",
        "  train_result = train_result.drop('is_train', axis=1)\n",
        "  test_result = test_result.drop('is_train', axis=1)\n",
        "\n",
        "  # add Survived\n",
        "  train_result['Survived'] = train['Survived']\n",
        "\n",
        "  # Delete Age and Fare\n",
        "  train_result = train_result.dropna(subset=['Age', 'Fare'])\n",
        "  test_result = test_result.fillna(test_result.mean())\n",
        "\n",
        "  return train_result, test_result\n",
        "\n",
        "# モデル作成\n",
        "def create_model(x):\n",
        "  network = models.Sequential()\n",
        "  network.add(layers.Dense(512, activation='relu', input_shape=(x.shape[1],)))\n",
        "  network.add(layers.Dense(10,activation='softmax'))\n",
        "  network.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  return network\n",
        "\n",
        "\n",
        "train, test = read_data()\n",
        "\n",
        "train, test = pre_processing(train, test)\n",
        "\n",
        "columns = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Ticket_Left']\n",
        "\n",
        "train_data = train[columns].values\n",
        "train_lavels = train['Survived'].values\n",
        "\n",
        "x_train = np.asarray(train_data).astype('float32')\n",
        "y_train = np.asarray(train_lavels).astype('float32')\n",
        "\n",
        "test_data = test[columns].values.astype('float32')\n",
        "\n",
        "\n",
        "#正規化\n",
        "for i in range(len(columns)-1):\n",
        "    mean = x_train.mean(axis=0)[i]\n",
        "    std = x_train.std(axis=0)[i]\n",
        "\n",
        "    x_train[:, i] = (x_train[:, i] - mean) / std\n",
        "    test_data[:, i] = (test_data[:, i] - mean) / std\n",
        "\n",
        "# create model\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(8, activation='relu', input_shape=(len(columns),)))\n",
        "model.add(layers.Dense(1,activation='softmax'))\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# fitting\n",
        "model.fit(x_train, y_train, epochs=3, batch_size=100)\n",
        "\n",
        "train_loss, train_acc = model.evaluate(x_train, y_train)\n",
        "print('train_acc : ', train_acc)\n",
        "\n",
        "Y_pred = model.predict(test_data)\n",
        "\n",
        "import csv\n",
        "with open(\"predict_result_data.csv\", \"w\") as f:\n",
        "    writer = csv.writer(f, lineterminator='\\n')\n",
        "    writer.writerow([\"PassengerId\", \"Survived\"])\n",
        "    for pid, survived in zip(test['PassengerId'].astype(int), Y_pred[:, 0].astype(int)):\n",
        "        writer.writerow([pid, survived])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train data reading...\n",
            "Train data is column 891, rows: 12\n",
            "Test data reading...\n",
            "Test data is column 418, rows: 11\n",
            "Combine train and test\n",
            "Modifying Sex column\n",
            "Modifying Ticket column\n",
            "Modifying Embarked column\n",
            "Modifying Cabin column\n",
            "Modifying Name column\n",
            "Split train and test\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/3\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "714/714 [==============================] - 1s 836us/step - loss: 9.4672 - acc: 0.4062\n",
            "Epoch 2/3\n",
            "714/714 [==============================] - 0s 17us/step - loss: 9.4672 - acc: 0.4062\n",
            "Epoch 3/3\n",
            "714/714 [==============================] - 0s 18us/step - loss: 9.4672 - acc: 0.4062\n",
            "714/714 [==============================] - 0s 48us/step\n",
            "train_acc :  0.4061624651529542\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}