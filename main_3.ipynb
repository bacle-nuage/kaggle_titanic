{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/you0229/kaggle_titanic/blob/master/main_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGwnZ6RpKtyn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "e2dce62b-310f-4a32-99b3-4f692dc2d1c1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1kWJckHDxQZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "046b73b6-b9f3-479c-88ee-fe23d614aae2"
      },
      "source": [
        "# libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Dropout\n",
        "import matplotlib.pyplot as plt\n",
        "# %matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdTrctLwDxgk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "COLAB_FLG = 1\n",
        "TRAIN_PATH = '/kaggle/input/titanic/train.csv'\n",
        "TEST_PATH = '/kaggle/input/titanic/test.csv'\n",
        "COLAB_TRAIN_PATH = '/content/drive/My Drive/MachineLeaning/kaggle_titanic/train.csv'\n",
        "COLAB_TEST_PATH = '/content/drive/My Drive/MachineLeaning/kaggle_titanic/test.csv'\n",
        "COLUMNS = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Ticket_Left']\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ha4PhCCD2af",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "##############################\n",
        "# データ読み込み\n",
        "##############################\n",
        "def read_data():\n",
        "  ## 読み込むデータのパス切り替え\n",
        "  if COLAB_FLG:\n",
        "    TRAIN_PATH = COLAB_TRAIN_PATH\n",
        "    TEST_PATH = COLAB_TEST_PATH\n",
        "  \n",
        "  print('Train data reading...')\n",
        "  train = pd.read_csv(TRAIN_PATH)\n",
        "  print(\"Train data is column {}, rows: {}\".format(train.shape[0], train.shape[1]))\n",
        "\n",
        "  print('Test data reading...')\n",
        "  test = pd.read_csv(TEST_PATH)\n",
        "  print(\"Test data is column {}, rows: {}\".format(test.shape[0], test.shape[1]))\n",
        "\n",
        "  return train, test"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oF2fFzoD7bZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "##############################\n",
        "# 前処理\n",
        "##############################\n",
        "def pre_processing(train, test):\n",
        "  # train と test を合わせて前処理\n",
        "  print('Combine train and test')\n",
        "  train['is_train'] = 1\n",
        "  test['is_train'] = 0\n",
        "  train_test = pd.concat([train.drop('Survived', axis=1),test], axis=0)\n",
        "\n",
        "  # Sex\n",
        "  print('Modifying Sex column')\n",
        "  train_test = train_test.replace('female', 0).replace('male', 1)\n",
        "\n",
        "  # Ticket\n",
        "  print('Modifying Ticket column')\n",
        "  ticket_to_num = {'A':0, 'P':1, 'S':2, '1':3, '3':4, '2':5, 'C':6, '7':7, 'W':8, '4':9, 'F':9, 'L':10, '9':11,'6':12, '5':13, '8':14}\n",
        "  train_test['Ticket_Left'] = train_test['Ticket'].apply(lambda x: str(x)[0])\n",
        "  train_test['Ticket_Left'] = train_test['Ticket_Left'].replace(ticket_to_num)\n",
        "  train_test = train_test.drop('Ticket', axis=1)\n",
        "\n",
        "  # Embarked\n",
        "  print('Modifying Embarked column')\n",
        "  embarked_to_num = {'S':0, 'C':1, 'Q':2}\n",
        "  train_test['Embarked'] = train_test['Embarked'].replace(embarked_to_num)\n",
        "  train_test['Embarked'] = train_test['Embarked'].fillna(train_test['Embarked'].mean())\n",
        "  train_test = train_test.drop('Embarked', axis=1)\n",
        "\n",
        "  # Cabin\n",
        "  # 204/891 したデータが入っていないため削除\n",
        "  print('Modifying Cabin column')\n",
        "  train_test = train_test.drop('Cabin', axis=1)\n",
        "\n",
        "  # Name\n",
        "  # 関係なさそうだから削除\n",
        "  print('Modifying Name column')\n",
        "  train_test = train_test.drop('Name', axis=1)\n",
        "\n",
        "  # train test\n",
        "  print('Split train and test')\n",
        "  train_result = train_test.loc[train_test['is_train'] == 1]\n",
        "  test_result = train_test.loc[train_test['is_train'] == 0]\n",
        "\n",
        "  train_result = train_result.drop('is_train', axis=1)\n",
        "  test_result = test_result.drop('is_train', axis=1)\n",
        "\n",
        "  # add Survived\n",
        "  train_result['Survived'] = train['Survived']\n",
        "\n",
        "  # Delete Age and Fare\n",
        "  train_result = train_result.dropna(subset=['Age', 'Fare'])\n",
        "  test_result = test_result.fillna(test_result.mean())\n",
        "\n",
        "  return train_result, test_result"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VCCI-usEGXD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "##############################\n",
        "# モデル構築 5層パーセプトロン\n",
        "##############################\n",
        "def create_model_5dim_layer(activation=\"relu\", optimizer=\"adam\", out_dim=100, dropout=0.5):\n",
        "    columns = COLUMNS\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    # 入力層 - 隠れ層1\n",
        "    model.add(Dense(input_dim=len(columns), units=out_dim))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation(activation))\n",
        "    model.add(Dropout(dropout))\n",
        "\n",
        "    # 隠れ層1 - 隠れ層2\n",
        "    model.add(Dense(units=out_dim))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation(activation))\n",
        "    model.add(Dropout(dropout))\n",
        "\n",
        "    # 隠れ層2 - 隠れ層3\n",
        "    model.add(Dense(units=out_dim))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation(activation))\n",
        "    model.add(Dropout(dropout))\n",
        "\n",
        "    # 隠れ層3 - 出力層\n",
        "    model.add(Dense(units=1))\n",
        "    model.add(Activation(\"sigmoid\"))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RD6-RJwnKUZx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "632c23cb-d3e8-4938-8ee2-29a30cb91abf"
      },
      "source": [
        "\n",
        "# データ読み込み\n",
        "train, test = read_data()\n",
        "\n",
        "# 前処理\n",
        "train, test = pre_processing(train, test)\n",
        "\n",
        "# 使用するカラム\n",
        "columns = COLUMNS\n",
        "train_data = train[columns].values\n",
        "train_lavels = train['Survived'].values\n",
        "\n",
        "# 型を変換\n",
        "x_train = np.asarray(train_data).astype('float32')\n",
        "y_train = np.asarray(train_lavels).astype('float32')\n",
        "test_data = test[columns].values.astype('float32')\n",
        "\n",
        "#正規化\n",
        "for i in range(len(columns)-1):\n",
        "    mean = x_train.mean(axis=0)[i]\n",
        "    std = x_train.std(axis=0)[i]\n",
        "\n",
        "    x_train[:, i] = (x_train[:, i] - mean) / std\n",
        "    test_data[:, i] = (test_data[:, i] - mean) / std\n",
        "\n",
        "# モデル作成\n",
        "# model = create_model_5dim_layer(columns)\n",
        "model = create_model_5dim_layer()\n",
        "\n",
        "# fitting\n",
        "model.fit(x_train, y_train, epochs=3, batch_size=100)\n",
        "\n",
        "# 点数算出\n",
        "train_loss, train_acc = model.evaluate(x_train, y_train)\n",
        "print('train_acc : ', train_acc)\n",
        "\n",
        "# テストデータを入力\n",
        "Y_pred = model.predict(test_data)\n",
        "\n",
        "import csv\n",
        "with open(\"predict_result_data.csv\", \"w\") as f:\n",
        "    writer = csv.writer(f, lineterminator='\\n')\n",
        "    writer.writerow([\"PassengerId\", \"Survived\"])\n",
        "    for pid, survived in zip(test['PassengerId'].astype(int), Y_pred[:, 0].astype(int)):\n",
        "        writer.writerow([pid, survived])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train data reading...\n",
            "Train data is column 891, rows: 12\n",
            "Test data reading...\n",
            "Test data is column 418, rows: 11\n",
            "Combine train and test\n",
            "Modifying Sex column\n",
            "Modifying Ticket column\n",
            "Modifying Embarked column\n",
            "Modifying Cabin column\n",
            "Modifying Name column\n",
            "Split train and test\n",
            "Epoch 1/3\n",
            "714/714 [==============================] - 1s 974us/step - loss: 0.8919 - accuracy: 0.5546\n",
            "Epoch 2/3\n",
            "714/714 [==============================] - 0s 47us/step - loss: 0.7372 - accuracy: 0.6008\n",
            "Epoch 3/3\n",
            "714/714 [==============================] - 0s 46us/step - loss: 0.6446 - accuracy: 0.6611\n",
            "714/714 [==============================] - 0s 138us/step\n",
            "train_acc :  0.732492983341217\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80OTc9dZ4O8Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "9ab92838-e82d-4e6c-8646-402ccac9af25"
      },
      "source": [
        "\n",
        "# データ読み込み\n",
        "train, test = read_data()\n",
        "\n",
        "# 前処理\n",
        "train, test = pre_processing(train, test)\n",
        "\n",
        "# 使用するカラム\n",
        "columns = COLUMNS\n",
        "train_data = train[columns].values\n",
        "train_lavels = train['Survived'].values\n",
        "\n",
        "# 型を変換\n",
        "x_train = np.asarray(train_data).astype('float32')\n",
        "y_train = np.asarray(train_lavels).astype('float32')\n",
        "test_data = test[columns].values.astype('float32')\n",
        "\n",
        "#正規化\n",
        "for i in range(len(columns)-1):\n",
        "    mean = x_train.mean(axis=0)[i]\n",
        "    std = x_train.std(axis=0)[i]\n",
        "\n",
        "    x_train[:, i] = (x_train[:, i] - mean) / std\n",
        "    test_data[:, i] = (test_data[:, i] - mean) / std\n",
        "\n",
        "##############################\n",
        "# GridSearch\n",
        "##############################\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "# model = KerasClassifier(build_fn=create_model_5dim_layer(columns), verbose=0)\n",
        "model = KerasClassifier(build_fn=create_model_5dim_layer, verbose=0)\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "# Define options for parameters\n",
        "activation = [\"tanh\", \"relu\"]\n",
        "optimizer = [\"adam\", \"adagrad\"]\n",
        "out_dim = [234, 468, 702]\n",
        "nb_epoch = [25, 50]\n",
        "batch_size = [8, 16]\n",
        "dropout = [0.2, 0.4, 0.5]\n",
        "\n",
        "param_grid = dict(activation=activation, \n",
        "                  optimizer=optimizer, \n",
        "                  out_dim=out_dim, \n",
        "                  nb_epoch=nb_epoch, \n",
        "                  batch_size=batch_size,\n",
        "                  dropout=dropout)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
        "\n",
        "# Run grid search\n",
        "grid_result = grid.fit(x_train, y_train)\n",
        "\n",
        "print(grid_result.best_score_)\n",
        "print(grid_result.best_params_)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train data reading...\n",
            "Train data is column 891, rows: 12\n",
            "Test data reading...\n",
            "Test data is column 418, rows: 11\n",
            "Combine train and test\n",
            "Modifying Sex column\n",
            "Modifying Ticket column\n",
            "Modifying Embarked column\n",
            "Modifying Cabin column\n",
            "Modifying Name column\n",
            "Split train and test\n",
            "0.7955579638481141\n",
            "{'activation': 'tanh', 'batch_size': 16, 'dropout': 0.5, 'nb_epoch': 25, 'optimizer': 'adagrad', 'out_dim': 234}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95h0i_oj0IKG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0aa6c3ec-993c-4b0c-99a7-1a900d6a61d7"
      },
      "source": [
        "\n",
        "# データ読み込み\n",
        "train, test = read_data()\n",
        "\n",
        "# 前処理\n",
        "train, test = pre_processing(train, test)\n",
        "\n",
        "# 使用するカラム\n",
        "columns = COLUMNS\n",
        "train_data = train[columns].values\n",
        "train_lavels = train['Survived'].values\n",
        "\n",
        "# 型を変換\n",
        "x_train = np.asarray(train_data).astype('float32')\n",
        "y_train = np.asarray(train_lavels).astype('float32')\n",
        "test_data = test[columns].values.astype('float32')\n",
        "\n",
        "#正規化\n",
        "for i in range(len(columns)-1):\n",
        "    mean = x_train.mean(axis=0)[i]\n",
        "    std = x_train.std(axis=0)[i]\n",
        "\n",
        "    x_train[:, i] = (x_train[:, i] - mean) / std\n",
        "    test_data[:, i] = (test_data[:, i] - mean) / std\n",
        "\n",
        "# モデル作成\n",
        "# model = create_model_5dim_layer(columns)\n",
        "# {'activation': 'tanh', 'batch_size': 16, 'dropout': 0.5, 'nb_epoch': 25, 'optimizer': 'adagrad', 'out_dim': 234}\n",
        "# create_model_5dim_layer(activation=\"relu\", optimizer=\"adam\", out_dim=100, dropout=0.5)\n",
        "activation = 'tanh'\n",
        "optimizer = 'adagrad'\n",
        "out_dim = 234\n",
        "dropout = 0.5\n",
        "batch_size = 16\n",
        "nb_epoch = 25\n",
        "\n",
        "model = create_model_5dim_layer(activation=activation, optimizer=optimizer, out_dim=out_dim)\n",
        "\n",
        "# fitting\n",
        "model.fit(x_train, y_train, epochs=nb_epoch, batch_size=batch_size)\n",
        "\n",
        "# 点数算出\n",
        "train_loss, train_acc = model.evaluate(x_train, y_train)\n",
        "print('train_acc : ', train_acc)\n",
        "\n",
        "# テストデータを入力\n",
        "Y_pred = model.predict(test_data)\n",
        "\n",
        "import csv\n",
        "with open(\"predict_result_data.csv\", \"w\") as f:\n",
        "    writer = csv.writer(f, lineterminator='\\n')\n",
        "    writer.writerow([\"PassengerId\", \"Survived\"])\n",
        "    for pid, survived in zip(test['PassengerId'].astype(int), Y_pred[:, 0].astype(int)):\n",
        "        writer.writerow([pid, survived])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train data reading...\n",
            "Train data is column 891, rows: 12\n",
            "Test data reading...\n",
            "Test data is column 418, rows: 11\n",
            "Combine train and test\n",
            "Modifying Sex column\n",
            "Modifying Ticket column\n",
            "Modifying Embarked column\n",
            "Modifying Cabin column\n",
            "Modifying Name column\n",
            "Split train and test\n",
            "Epoch 1/25\n",
            "714/714 [==============================] - 1s 1ms/step - loss: 0.6602 - accuracy: 0.7381\n",
            "Epoch 2/25\n",
            "714/714 [==============================] - 0s 257us/step - loss: 0.5738 - accuracy: 0.7297\n",
            "Epoch 3/25\n",
            "714/714 [==============================] - 0s 278us/step - loss: 0.5605 - accuracy: 0.7479\n",
            "Epoch 4/25\n",
            "714/714 [==============================] - 0s 253us/step - loss: 0.5552 - accuracy: 0.7353\n",
            "Epoch 5/25\n",
            "714/714 [==============================] - 0s 235us/step - loss: 0.5294 - accuracy: 0.7563\n",
            "Epoch 6/25\n",
            "714/714 [==============================] - 0s 255us/step - loss: 0.5283 - accuracy: 0.7647\n",
            "Epoch 7/25\n",
            "714/714 [==============================] - 0s 268us/step - loss: 0.5248 - accuracy: 0.7703\n",
            "Epoch 8/25\n",
            "714/714 [==============================] - 0s 248us/step - loss: 0.4957 - accuracy: 0.7997\n",
            "Epoch 9/25\n",
            "714/714 [==============================] - 0s 262us/step - loss: 0.5129 - accuracy: 0.7577\n",
            "Epoch 10/25\n",
            "714/714 [==============================] - 0s 248us/step - loss: 0.4996 - accuracy: 0.7829\n",
            "Epoch 11/25\n",
            "714/714 [==============================] - 0s 255us/step - loss: 0.4960 - accuracy: 0.7731\n",
            "Epoch 12/25\n",
            "714/714 [==============================] - 0s 246us/step - loss: 0.5089 - accuracy: 0.7731\n",
            "Epoch 13/25\n",
            "714/714 [==============================] - 0s 269us/step - loss: 0.5140 - accuracy: 0.7759\n",
            "Epoch 14/25\n",
            "714/714 [==============================] - 0s 272us/step - loss: 0.4824 - accuracy: 0.7885\n",
            "Epoch 15/25\n",
            "714/714 [==============================] - 0s 269us/step - loss: 0.4957 - accuracy: 0.7829\n",
            "Epoch 16/25\n",
            "714/714 [==============================] - 0s 258us/step - loss: 0.5048 - accuracy: 0.7731\n",
            "Epoch 17/25\n",
            "714/714 [==============================] - 0s 246us/step - loss: 0.4691 - accuracy: 0.7913\n",
            "Epoch 18/25\n",
            "714/714 [==============================] - 0s 251us/step - loss: 0.4790 - accuracy: 0.7843\n",
            "Epoch 19/25\n",
            "714/714 [==============================] - 0s 267us/step - loss: 0.4773 - accuracy: 0.7899\n",
            "Epoch 20/25\n",
            "714/714 [==============================] - 0s 262us/step - loss: 0.4829 - accuracy: 0.7843\n",
            "Epoch 21/25\n",
            "714/714 [==============================] - 0s 253us/step - loss: 0.5005 - accuracy: 0.7773\n",
            "Epoch 22/25\n",
            "714/714 [==============================] - 0s 246us/step - loss: 0.4913 - accuracy: 0.7731\n",
            "Epoch 23/25\n",
            "714/714 [==============================] - 0s 262us/step - loss: 0.4619 - accuracy: 0.8081\n",
            "Epoch 24/25\n",
            "714/714 [==============================] - 0s 242us/step - loss: 0.4610 - accuracy: 0.7983\n",
            "Epoch 25/25\n",
            "714/714 [==============================] - 0s 262us/step - loss: 0.4707 - accuracy: 0.8081\n",
            "714/714 [==============================] - 0s 151us/step\n",
            "train_acc :  0.82492995262146\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}