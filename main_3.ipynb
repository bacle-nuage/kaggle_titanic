{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/you0229/kaggle_titanic/blob/master/main_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGwnZ6RpKtyn",
        "colab_type": "code",
        "outputId": "35c1bb48-fc23-4bbb-da54-e66f464bbef8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RD6-RJwnKUZx",
        "colab_type": "code",
        "outputId": "70fc69b1-bb62-4f44-bfb9-783f9762b543",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        }
      },
      "source": [
        "# libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Dropout\n",
        "import matplotlib.pyplot as plt\n",
        "# %matplotlib inline\n",
        "\n",
        "COLAB_FLG = 1\n",
        "TRAIN_PATH = '/kaggle/input/titanic/train.csv'\n",
        "TEST_PATH = '/kaggle/input/titanic/test.csv'\n",
        "COLAB_TRAIN_PATH = '/content/drive/My Drive/MachineLeaning/kaggle_titanic/train.csv'\n",
        "COLAB_TEST_PATH = '/content/drive/My Drive/MachineLeaning/kaggle_titanic/test.csv'\n",
        "\n",
        "##############################\n",
        "# データ読み込み\n",
        "##############################\n",
        "def read_data():\n",
        "  ## 読み込むデータのパス切り替え\n",
        "  if COLAB_FLG:\n",
        "    TRAIN_PATH = COLAB_TRAIN_PATH\n",
        "    TEST_PATH = COLAB_TEST_PATH\n",
        "  \n",
        "  print('Train data reading...')\n",
        "  train = pd.read_csv(TRAIN_PATH)\n",
        "  print(\"Train data is column {}, rows: {}\".format(train.shape[0], train.shape[1]))\n",
        "\n",
        "  print('Test data reading...')\n",
        "  test = pd.read_csv(TEST_PATH)\n",
        "  print(\"Test data is column {}, rows: {}\".format(test.shape[0], test.shape[1]))\n",
        "\n",
        "  return train, test\n",
        "\n",
        "##############################\n",
        "# 前処理\n",
        "##############################\n",
        "def pre_processing(train, test):\n",
        "  # train と test を合わせて前処理\n",
        "  print('Combine train and test')\n",
        "  train['is_train'] = 1\n",
        "  test['is_train'] = 0\n",
        "  train_test = pd.concat([train.drop('Survived', axis=1),test], axis=0)\n",
        "\n",
        "  # Sex\n",
        "  print('Modifying Sex column')\n",
        "  train_test = train_test.replace('female', 0).replace('male', 1)\n",
        "\n",
        "  # Ticket\n",
        "  print('Modifying Ticket column')\n",
        "  ticket_to_num = {'A':0, 'P':1, 'S':2, '1':3, '3':4, '2':5, 'C':6, '7':7, 'W':8, '4':9, 'F':9, 'L':10, '9':11,'6':12, '5':13, '8':14}\n",
        "  train_test['Ticket_Left'] = train_test['Ticket'].apply(lambda x: str(x)[0])\n",
        "  train_test['Ticket_Left'] = train_test['Ticket_Left'].replace(ticket_to_num)\n",
        "  train_test = train_test.drop('Ticket', axis=1)\n",
        "\n",
        "  # Embarked\n",
        "  print('Modifying Embarked column')\n",
        "  embarked_to_num = {'S':0, 'C':1, 'Q':2}\n",
        "  train_test['Embarked'] = train_test['Embarked'].replace(embarked_to_num)\n",
        "  train_test['Embarked'] = train_test['Embarked'].fillna(train_test['Embarked'].mean())\n",
        "  train_test = train_test.drop('Embarked', axis=1)\n",
        "\n",
        "  # Cabin\n",
        "  # 204/891 したデータが入っていないため削除\n",
        "  print('Modifying Cabin column')\n",
        "  train_test = train_test.drop('Cabin', axis=1)\n",
        "\n",
        "  # Name\n",
        "  # 関係なさそうだから削除\n",
        "  print('Modifying Name column')\n",
        "  train_test = train_test.drop('Name', axis=1)\n",
        "\n",
        "  # train test\n",
        "  print('Split train and test')\n",
        "  train_result = train_test.loc[train_test['is_train'] == 1]\n",
        "  test_result = train_test.loc[train_test['is_train'] == 0]\n",
        "\n",
        "  train_result = train_result.drop('is_train', axis=1)\n",
        "  test_result = test_result.drop('is_train', axis=1)\n",
        "\n",
        "  # add Survived\n",
        "  train_result['Survived'] = train['Survived']\n",
        "\n",
        "  # Delete Age and Fare\n",
        "  train_result = train_result.dropna(subset=['Age', 'Fare'])\n",
        "  test_result = test_result.fillna(test_result.mean())\n",
        "\n",
        "  return train_result, test_result\n",
        "\n",
        "##############################\n",
        "# モデル構築 5層パーセプトロン\n",
        "##############################\n",
        "def create_model_5dim_layer(columns, activation=\"relu\", optimizer=\"adam\", out_dim=100, dropout=0.5):\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    # 入力層 - 隠れ層1\n",
        "    model.add(Dense(input_dim=len(columns), units=out_dim))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation(activation))\n",
        "    model.add(Dropout(dropout))\n",
        "\n",
        "    # 隠れ層1 - 隠れ層2\n",
        "    model.add(Dense(units=out_dim))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation(activation))\n",
        "    model.add(Dropout(dropout))\n",
        "\n",
        "    # 隠れ層2 - 隠れ層3\n",
        "    model.add(Dense(units=out_dim))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation(activation))\n",
        "    model.add(Dropout(dropout))\n",
        "\n",
        "    # 隠れ層3 - 出力層\n",
        "    model.add(Dense(units=1))\n",
        "    model.add(Activation(\"sigmoid\"))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# データ読み込み\n",
        "train, test = read_data()\n",
        "\n",
        "# 前処理\n",
        "train, test = pre_processing(train, test)\n",
        "\n",
        "# 使用するカラム\n",
        "columns = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Ticket_Left']\n",
        "train_data = train[columns].values\n",
        "train_lavels = train['Survived'].values\n",
        "\n",
        "# 型を変換\n",
        "x_train = np.asarray(train_data).astype('float32')\n",
        "y_train = np.asarray(train_lavels).astype('float32')\n",
        "test_data = test[columns].values.astype('float32')\n",
        "\n",
        "#正規化\n",
        "for i in range(len(columns)-1):\n",
        "    mean = x_train.mean(axis=0)[i]\n",
        "    std = x_train.std(axis=0)[i]\n",
        "\n",
        "    x_train[:, i] = (x_train[:, i] - mean) / std\n",
        "    test_data[:, i] = (test_data[:, i] - mean) / std\n",
        "\n",
        "# モデル作成\n",
        "model = create_model_5dim_layer(columns)\n",
        "\n",
        "# fitting\n",
        "model.fit(x_train, y_train, epochs=3, batch_size=100)\n",
        "\n",
        "# 点数算出\n",
        "train_loss, train_acc = model.evaluate(x_train, y_train)\n",
        "print('train_acc : ', train_acc)\n",
        "\n",
        "# テストデータを入力\n",
        "Y_pred = model.predict(test_data)\n",
        "\n",
        "import csv\n",
        "with open(\"predict_result_data.csv\", \"w\") as f:\n",
        "    writer = csv.writer(f, lineterminator='\\n')\n",
        "    writer.writerow([\"PassengerId\", \"Survived\"])\n",
        "    for pid, survived in zip(test['PassengerId'].astype(int), Y_pred[:, 0].astype(int)):\n",
        "        writer.writerow([pid, survived])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train data reading...\n",
            "Train data is column 891, rows: 12\n",
            "Test data reading...\n",
            "Test data is column 418, rows: 11\n",
            "Combine train and test\n",
            "Modifying Sex column\n",
            "Modifying Ticket column\n",
            "Modifying Embarked column\n",
            "Modifying Cabin column\n",
            "Modifying Name column\n",
            "Split train and test\n",
            "Epoch 1/3\n",
            "714/714 [==============================] - 1s 949us/step - loss: 0.9439 - accuracy: 0.4566\n",
            "Epoch 2/3\n",
            "714/714 [==============================] - 0s 37us/step - loss: 0.7631 - accuracy: 0.5728\n",
            "Epoch 3/3\n",
            "714/714 [==============================] - 0s 35us/step - loss: 0.7066 - accuracy: 0.6345\n",
            "714/714 [==============================] - 0s 112us/step\n",
            "train_acc :  0.7296918630599976\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80OTc9dZ4O8Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "d97ac59a-3a7b-43e8-eefc-91e86e63461c"
      },
      "source": [
        "\"\"\"\n",
        "##############################\n",
        "# GridSearch\n",
        "##############################\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "model = KerasClassifier(build_fn=create_model_5dim_layer(columns), verbose=0)\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "# Define options for parameters\n",
        "activation = [\"tanh\", \"relu\"]\n",
        "optimizer = [\"adam\", \"adagrad\"]\n",
        "out_dim = [234, 468, 702]\n",
        "nb_epoch = [25, 50]\n",
        "batch_size = [8, 16]\n",
        "dropout = [0.2, 0.4, 0.5]\n",
        "\n",
        "param_grid = dict(activation=activation, \n",
        "                  optimizer=optimizer, \n",
        "                  out_dim=out_dim, \n",
        "                  nb_epoch=nb_epoch, \n",
        "                  batch_size=batch_size,\n",
        "                  dropout=dropout)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
        "\n",
        "# Run grid search\n",
        "grid_result = grid.fit(x_train, y_train)\n",
        "\n",
        "print(grid_result.best_score_)\n",
        "print(grid_result.best_params_)\n",
        "\"\"\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'from sklearn.model_selection import GridSearchCV\\n# Define options for parameters\\nactivation = [\"tanh\", \"relu\"]\\noptimizer = [\"adam\", \"adagrad\"]\\nout_dim = [234, 468, 702]\\nnb_epoch = [25, 50]\\nbatch_size = [8, 16]\\ndropout = [0.2, 0.4, 0.5]\\n\\nparam_grid = dict(activation=activation, \\n                  optimizer=optimizer, \\n                  out_dim=out_dim, \\n                  nb_epoch=nb_epoch, \\n                  batch_size=batch_size,\\n                  dropout=dropout)\\ngrid = GridSearchCV(estimator=model, param_grid=param_grid)\\n\\n# Run grid search\\ngrid_result = grid.fit(x_train, y_train)\\n\\nprint(grid_result.best_score_)\\nprint(grid_result.best_params_)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwidzyufH3mo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}